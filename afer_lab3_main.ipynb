{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим наша датасет, которые использовался ранее в предыдущих работах. (https://www.kaggle.com/laotse/credit-risk-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на наш датасет, что бы убедиться, что все корретно считалось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>D</td>\n",
       "      <td>35000</td>\n",
       "      <td>16.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          22          59000                  RENT              123.0   \n",
       "1          21           9600                   OWN                5.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "0    PERSONAL          D      35000          16.02            1   \n",
       "1   EDUCATION          B       1000          11.14            0   \n",
       "\n",
       "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                 0.59                         Y                           3  \n",
       "1                 0.10                         N                           2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32579</th>\n",
       "      <td>56</td>\n",
       "      <td>150000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>B</td>\n",
       "      <td>15000</td>\n",
       "      <td>11.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32580</th>\n",
       "      <td>66</td>\n",
       "      <td>42000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>B</td>\n",
       "      <td>6475</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>N</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "32579          56         150000              MORTGAGE                5.0   \n",
       "32580          66          42000                  RENT                2.0   \n",
       "\n",
       "      loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "32579    PERSONAL          B      15000          11.48            0   \n",
       "32580     MEDICAL          B       6475           9.99            0   \n",
       "\n",
       "       loan_percent_income cb_person_default_on_file  \\\n",
       "32579                 0.10                         N   \n",
       "32580                 0.15                         N   \n",
       "\n",
       "       cb_person_cred_hist_length  \n",
       "32579                          26  \n",
       "32580                          30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все хорошо, продолжаем работу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как наш датасет связан с кредитным скорингом, то мы будем предсказывать вероятность принадлежность к одному из классов {0, 1} нашего целевого признака **loan_status**, где 1 обозначает очень сильную уверенность в том, что человеку можно выдать кредит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как некоторые объекты в данных описываются категориальными признаками применин к ниму one-hot-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = pd.DataFrame(df[df.select_dtypes(['int64', 'float64']).columns])\n",
    "categorial_features = pd.DataFrame(pd.DataFrame(df[df.select_dtypes(['object']).columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding_features = pd.get_dummies(categorial_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_home_ownership_MORTGAGE</th>\n",
       "      <th>person_home_ownership_OTHER</th>\n",
       "      <th>person_home_ownership_OWN</th>\n",
       "      <th>person_home_ownership_RENT</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "      <th>loan_grade_A</th>\n",
       "      <th>loan_grade_B</th>\n",
       "      <th>loan_grade_C</th>\n",
       "      <th>loan_grade_D</th>\n",
       "      <th>loan_grade_E</th>\n",
       "      <th>loan_grade_F</th>\n",
       "      <th>loan_grade_G</th>\n",
       "      <th>cb_person_default_on_file_N</th>\n",
       "      <th>cb_person_default_on_file_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32576</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32577</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32578</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32579</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32580</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32581 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_home_ownership_MORTGAGE  person_home_ownership_OTHER  \\\n",
       "0                                   0                            0   \n",
       "1                                   0                            0   \n",
       "2                                   1                            0   \n",
       "3                                   0                            0   \n",
       "4                                   0                            0   \n",
       "...                               ...                          ...   \n",
       "32576                               1                            0   \n",
       "32577                               1                            0   \n",
       "32578                               0                            0   \n",
       "32579                               1                            0   \n",
       "32580                               0                            0   \n",
       "\n",
       "       person_home_ownership_OWN  person_home_ownership_RENT  \\\n",
       "0                              0                           1   \n",
       "1                              1                           0   \n",
       "2                              0                           0   \n",
       "3                              0                           1   \n",
       "4                              0                           1   \n",
       "...                          ...                         ...   \n",
       "32576                          0                           0   \n",
       "32577                          0                           0   \n",
       "32578                          0                           1   \n",
       "32579                          0                           0   \n",
       "32580                          0                           1   \n",
       "\n",
       "       loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "0                                  0                      0   \n",
       "1                                  0                      1   \n",
       "2                                  0                      0   \n",
       "3                                  0                      0   \n",
       "4                                  0                      0   \n",
       "...                              ...                    ...   \n",
       "32576                              0                      0   \n",
       "32577                              0                      0   \n",
       "32578                              0                      0   \n",
       "32579                              0                      0   \n",
       "32580                              0                      0   \n",
       "\n",
       "       loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "0                                0                    0                     1   \n",
       "1                                0                    0                     0   \n",
       "2                                0                    1                     0   \n",
       "3                                0                    1                     0   \n",
       "4                                0                    1                     0   \n",
       "...                            ...                  ...                   ...   \n",
       "32576                            0                    0                     1   \n",
       "32577                            0                    0                     1   \n",
       "32578                            1                    0                     0   \n",
       "32579                            0                    0                     1   \n",
       "32580                            0                    1                     0   \n",
       "\n",
       "       loan_intent_VENTURE  loan_grade_A  loan_grade_B  loan_grade_C  \\\n",
       "0                        0             0             0             0   \n",
       "1                        0             0             1             0   \n",
       "2                        0             0             0             1   \n",
       "3                        0             0             0             1   \n",
       "4                        0             0             0             1   \n",
       "...                    ...           ...           ...           ...   \n",
       "32576                    0             0             0             1   \n",
       "32577                    0             1             0             0   \n",
       "32578                    0             0             1             0   \n",
       "32579                    0             0             1             0   \n",
       "32580                    0             0             1             0   \n",
       "\n",
       "       loan_grade_D  loan_grade_E  loan_grade_F  loan_grade_G  \\\n",
       "0                 1             0             0             0   \n",
       "1                 0             0             0             0   \n",
       "2                 0             0             0             0   \n",
       "3                 0             0             0             0   \n",
       "4                 0             0             0             0   \n",
       "...             ...           ...           ...           ...   \n",
       "32576             0             0             0             0   \n",
       "32577             0             0             0             0   \n",
       "32578             0             0             0             0   \n",
       "32579             0             0             0             0   \n",
       "32580             0             0             0             0   \n",
       "\n",
       "       cb_person_default_on_file_N  cb_person_default_on_file_Y  \n",
       "0                                0                            1  \n",
       "1                                1                            0  \n",
       "2                                1                            0  \n",
       "3                                1                            0  \n",
       "4                                0                            1  \n",
       "...                            ...                          ...  \n",
       "32576                            1                            0  \n",
       "32577                            1                            0  \n",
       "32578                            1                            0  \n",
       "32579                            1                            0  \n",
       "32580                            1                            0  \n",
       "\n",
       "[32581 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим закодированные категориальные признаки к нашим числовым данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.hstack([numerical_features, one_hot_encoding_features]),\n",
    "                 columns=list(numerical_features.columns) + list(one_hot_encoding_features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (32581, 27)\n"
     ]
    }
   ],
   "source": [
    "print(f'X shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге мы имеем 8 числовых признаков (среди которых один является таргетом), и 19 признаков которые появлись в следствии one-hot-encoding (можно заметить, что категориальные значения принимают довольно малое число уникальных значений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь отделим от данных основной таргет (признак **loan_status**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = X['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестировать мы будем логистическую регресиию, которая представлена в sklearn классом LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу следует обозначить следующую проблему - это масштаб и смещение признаков. Это заставляется хуже работать логистическую регрессию, так как она использует регуляризацию, то есть мы штрафуем модель за большие веса для признаков, тем самым заставляя их быть как можно меньше, а различный масштаб признаков плохо сочетается с этим. (то есть может возникнуть ситуация когда мы выбираем более далекое от правильно решения, но с маленькими весами, вместо решения у которого некоторые веса могут быть достаточно большими (из-за естественной потребности, потому что масштаб разный), но которое довольно близко к настоящему решению).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому по причиве выше нам необходимо нормировать наши данные, а уже потом тестировать различные комбинации которые предлагаются в лабораторной работе. (заполнять или не заполнять пропуски, сглаживать или не сглаживать данные)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее что бы получить более \"хорошие\" данные (тут более \"хорошие\" необходимо понимать в относительном смысле, потому что гиперпараметры мы будем подбирать при фиксированной метрике roc_auc и на одной конректной параметризации входных данных, но в среднем стоит ожидать улучшения результатов), сначала подберем некоторые гиперпараметры нашей модели. Так как sklearn по умолчанию использую L2 регуляризацию, необходимо подбирать коэффициент C, который отвечает за \"силу\" регуляризации. Но кроме этого подберем еще коэффициент l1_ration, которые отвечает за долю смешания L1 ти L2 регуляризаций, то есть в конечном итоге получим такую сместь l1_ratio * L1 + (1 - l1_ration) * L2, то есть в итоге мы будем использовать так называемую elasticnet регуляризацию.\n",
    "\n",
    "Подбирать гиперпараметры будем на данных из которых предварительно выкинем все объекты по которым имеются пропуски, после этого отнормируем данные и будем подбирать гиперпараметры на кросс-валидации с 5 фолдами. А потом имею уже в некоторой мере \"хорошые\" гиперпараметры для нашей логистической регрессии начнем основное тестирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"C\" : np.linspace(0.001, 100, 30),\n",
    "    \"l1_ratio\" : np.linspace(0, 1, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(LogisticRegression(penalty='elasticnet', solver='saga'), \n",
    "                       params_grid, cv=KFold(5), scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подготовим данные для обучения на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.hstack([X, target[:, np.newaxis]]), columns=list(X.columns) + ['loan_status'])\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_local = data[data.columns[: -1]]\n",
    "target_local = data[data.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_local = scaler.fit_transform(X_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь начинаем перебор по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='elasticnet',\n",
       "                                          random_state=None, solver='saga',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated...\n",
       "       6.89658276e+01, 7.24140690e+01, 7.58623103e+01, 7.93105517e+01,\n",
       "       8.27587931e+01, 8.62070345e+01, 8.96552759e+01, 9.31035172e+01,\n",
       "       9.65517586e+01, 1.00000000e+02]),\n",
       "                         'l1_ratio': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.fit(X_local, target_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.8679366581480856 on {'C': 3.4492413793103447, 'l1_ratio': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(f'best score {grid_cv.best_score_} on {grid_cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, получили неплохие результаты относительно метрики roc_auc. Далее продолжим работать с логистической регрессией с гиперпараметрами C = 3.449241 и l1_ration = 2/3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь начнем наше тестирования, для этого напишем необходимые функции. Для заполнения данных будем использовать SimpleImputer(strategy='mean') (можно было бы попробовать использовать KNNImputer, но он работает за квадратичное время от количества объектов, а их у нас много...) и для сглаживание данных - экспоненциальное сглаживание.\n",
    "\n",
    "В качестве метрик будем использовать 'roc-auc', 'f1-macro', 'accuracy', 'precision' - классический выбор для задач классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(values):\n",
    "    fit_data = SimpleExpSmoothing(values, initialization_method=\"estimated\").\\\n",
    "                fit(smoothing_level=0.2,optimized=False)\n",
    "    return fit_data.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropna_numpy(x):\n",
    "    original_shape = x.shape\n",
    "    return x[~np.isnan(x)].reshape(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropna_dataset(X, y):\n",
    "    train_full = np.hstack([X, y[:, np.newaxis]])\n",
    "    train_full = pd.DataFrame(train_full).dropna().to_numpy()\n",
    "    X_train = train_full[:, :-1]\n",
    "    y_train = train_full[:, -1]\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_correspond_y_target = pd.concat([X, target], axis=1).dropna()['loan_status']\n",
    "smooth_data_with_drop_na = X.dropna().apply(smooth_data, axis=0)\n",
    "simple_imputer = SimpleImputer(strategy='mean')\n",
    "smooth_data_with_fill_na = pd.DataFrame(simple_imputer.fit_transform(X)).apply(smooth_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(clf, X, target, train_size, fill_na, smooth, metric_calc, metric_name, output_result,\n",
    "                    smooth_data_with_drop_na, smooth_correspond_y_target, smooth_data_with_fill_na):\n",
    "    if smooth and fill_na:\n",
    "        X = smooth_data_with_fill_na\n",
    "    elif smooth and not fill_na:\n",
    "        X = smooth_data_with_drop_na\n",
    "        target = smooth_correspond_y_target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=1-train_size, random_state=42)\n",
    "    \n",
    "    if fill_na:\n",
    "        knn_imputer = SimpleImputer(strategy='mean')\n",
    "        knn_imputer.fit(X_train)\n",
    "        X_train = knn_imputer.transform(X_train)\n",
    "        X_test = knn_imputer.transform(X_test)\n",
    "    else:\n",
    "        X_train, y_train = dropna_dataset(X_train, y_train)\n",
    "        X_test, y_test = dropna_dataset(X_test, y_test)\n",
    "       \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    if metric_name == 'auc_roc':\n",
    "        score = metric_calc(y_test, predict_prob)\n",
    "    else:\n",
    "        score = metric_calc(y_test, clf.predict(X_test))\n",
    "    \n",
    "    if fill_na and smooth:\n",
    "        index_name = 'fill_na & smooth'\n",
    "    elif not fill_na and smooth:\n",
    "        index_name = 'non fill_na & smooth'\n",
    "    elif fill_na and not smooth:\n",
    "        index_name = 'fill_na & non smooth'\n",
    "    else:\n",
    "        index_name = 'non fill_na & non smooth'\n",
    "    \n",
    "    \n",
    "    output_result.loc[index_name, metric_name] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем датафрейм для вывода результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_output = list([f'{np.round(train_size, 1)}/{np.round(1 - train_size, 1)}', \n",
    "                            'non fill_na & smooth', 'fill_na & smooth', \n",
    "                            'non fill_na & non smooth', 'fill_na & non smooth']\n",
    "                          for train_size in [0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_output = ['roc-auc', 'f1-macro', 'accuracy', 'precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'roc-auc': roc_auc_score,\n",
    "    'f1-macro': f1_score,\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter_idx, train_size in enumerate([0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "    local_results = pd.DataFrame(columns=columns_output, index=index_output[iter_idx])\n",
    "    for fill_na in [True, False]:\n",
    "        for smooth in [True, False]:\n",
    "            for metric_name in ['roc-auc', 'f1-macro', 'accuracy', 'precision']:\n",
    "                test_classifier(LogisticRegression(penalty='elasticnet', solver='saga', \n",
    "                                                  **grid_cv.best_params_),\n",
    "                                X, target, train_size, fill_na, smooth, metrics[metric_name], metric_name,\n",
    "                                local_results, smooth_data_with_drop_na, \n",
    "                                smooth_correspond_y_target, smooth_data_with_fill_na)\n",
    "    output_results.append(local_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([output_results[idx] for idx in range(len(output_results))], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конечном итоге имеем следующие результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc-auc</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5/0.5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; smooth</th>\n",
       "      <td>0.528338</td>\n",
       "      <td>0.119802</td>\n",
       "      <td>0.788603</td>\n",
       "      <td>0.668831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; smooth</th>\n",
       "      <td>0.526787</td>\n",
       "      <td>0.112545</td>\n",
       "      <td>0.788963</td>\n",
       "      <td>0.689873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; non smooth</th>\n",
       "      <td>0.754907</td>\n",
       "      <td>0.645221</td>\n",
       "      <td>0.866452</td>\n",
       "      <td>0.766343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; non smooth</th>\n",
       "      <td>0.754731</td>\n",
       "      <td>0.644972</td>\n",
       "      <td>0.866061</td>\n",
       "      <td>0.765842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6/0.4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; smooth</th>\n",
       "      <td>0.528925</td>\n",
       "      <td>0.123681</td>\n",
       "      <td>0.789717</td>\n",
       "      <td>0.641509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; smooth</th>\n",
       "      <td>0.525535</td>\n",
       "      <td>0.108962</td>\n",
       "      <td>0.787923</td>\n",
       "      <td>0.667984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; non smooth</th>\n",
       "      <td>0.759119</td>\n",
       "      <td>0.652023</td>\n",
       "      <td>0.868317</td>\n",
       "      <td>0.770071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; non smooth</th>\n",
       "      <td>0.758266</td>\n",
       "      <td>0.650607</td>\n",
       "      <td>0.867567</td>\n",
       "      <td>0.768532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7/0.3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; smooth</th>\n",
       "      <td>0.528149</td>\n",
       "      <td>0.119302</td>\n",
       "      <td>0.788641</td>\n",
       "      <td>0.664865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; smooth</th>\n",
       "      <td>0.526752</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.786189</td>\n",
       "      <td>0.685567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; non smooth</th>\n",
       "      <td>0.758492</td>\n",
       "      <td>0.651974</td>\n",
       "      <td>0.86708</td>\n",
       "      <td>0.772299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; non smooth</th>\n",
       "      <td>0.755065</td>\n",
       "      <td>0.646964</td>\n",
       "      <td>0.865575</td>\n",
       "      <td>0.771795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8/0.2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; smooth</th>\n",
       "      <td>0.52763</td>\n",
       "      <td>0.116726</td>\n",
       "      <td>0.783345</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; smooth</th>\n",
       "      <td>0.524827</td>\n",
       "      <td>0.10687</td>\n",
       "      <td>0.784563</td>\n",
       "      <td>0.661417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; non smooth</th>\n",
       "      <td>0.753996</td>\n",
       "      <td>0.644506</td>\n",
       "      <td>0.865338</td>\n",
       "      <td>0.767877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; non smooth</th>\n",
       "      <td>0.749351</td>\n",
       "      <td>0.637833</td>\n",
       "      <td>0.862513</td>\n",
       "      <td>0.766764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9/0.1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; smooth</th>\n",
       "      <td>0.522052</td>\n",
       "      <td>0.101597</td>\n",
       "      <td>0.783869</td>\n",
       "      <td>0.57377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; smooth</th>\n",
       "      <td>0.524986</td>\n",
       "      <td>0.106926</td>\n",
       "      <td>0.774471</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non fill_na &amp; non smooth</th>\n",
       "      <td>0.747046</td>\n",
       "      <td>0.639432</td>\n",
       "      <td>0.857744</td>\n",
       "      <td>0.786026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill_na &amp; non smooth</th>\n",
       "      <td>0.745257</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.857625</td>\n",
       "      <td>0.7853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           roc-auc  f1-macro  accuracy precision\n",
       "0.5/0.5                        NaN       NaN       NaN       NaN\n",
       "non fill_na & smooth      0.528338  0.119802  0.788603  0.668831\n",
       "fill_na & smooth          0.526787  0.112545  0.788963  0.689873\n",
       "non fill_na & non smooth  0.754907  0.645221  0.866452  0.766343\n",
       "fill_na & non smooth      0.754731  0.644972  0.866061  0.765842\n",
       "0.6/0.4                        NaN       NaN       NaN       NaN\n",
       "non fill_na & smooth      0.528925  0.123681  0.789717  0.641509\n",
       "fill_na & smooth          0.525535  0.108962  0.787923  0.667984\n",
       "non fill_na & non smooth  0.759119  0.652023  0.868317  0.770071\n",
       "fill_na & non smooth      0.758266  0.650607  0.867567  0.768532\n",
       "0.7/0.3                        NaN       NaN       NaN       NaN\n",
       "non fill_na & smooth      0.528149  0.119302  0.788641  0.664865\n",
       "fill_na & smooth          0.526752  0.112903  0.786189  0.685567\n",
       "non fill_na & non smooth  0.758492  0.651974   0.86708  0.772299\n",
       "fill_na & non smooth      0.755065  0.646964  0.865575  0.771795\n",
       "0.8/0.2                        NaN       NaN       NaN       NaN\n",
       "non fill_na & smooth       0.52763  0.116726  0.783345  0.683333\n",
       "fill_na & smooth          0.524827   0.10687  0.784563  0.661417\n",
       "non fill_na & non smooth  0.753996  0.644506  0.865338  0.767877\n",
       "fill_na & non smooth      0.749351  0.637833  0.862513  0.766764\n",
       "0.9/0.1                        NaN       NaN       NaN       NaN\n",
       "non fill_na & smooth      0.522052  0.101597  0.783869   0.57377\n",
       "fill_na & smooth          0.524986  0.106926  0.774471    0.6875\n",
       "non fill_na & non smooth  0.747046  0.639432  0.857744  0.786026\n",
       "fill_na & non smooth      0.745257  0.636364  0.857625    0.7853"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать следующий вывод, выбор пропорции разбиения — компромисс. Действительно, большой размер обучения ведет к более качественным алгоритмам, но бОльшему шуму при оценке модели на тесте. И наоборот, большой размер тестовой выборки ведет к менее шумной оценке качества, однако обученные модели получаются менее точными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы могли столкнуться с насыщение нашего алгоритма, когда добавление новых наблюдений в выборке не добавляет качества, и отчасти могли столкнуться с переобучением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экспоненциальное сглаживание по всем столбцам в целом ухудшало результат, это можно объяснить тем, что мы теряли нужную нам информацию для обучения или \"отходя\" дальше от линейного вида зависимости в пространстве признаков, и также природой нашей данных, которые не имееют в себе временной составляющей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
